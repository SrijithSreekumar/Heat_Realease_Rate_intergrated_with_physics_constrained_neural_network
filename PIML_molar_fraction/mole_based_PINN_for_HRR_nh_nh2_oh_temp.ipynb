{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mole_based_PINN_for_HRR_nh_nh2_oh_temp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Module Import "
      ],
      "metadata": {
        "id": "EwQA-iFUQGkA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA7tlFRBP5WD",
        "outputId": "77a6a2c0-63f1-458b-8e94-84640b7f5748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import re\n",
        "import os\n",
        "import time as t\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "np.set_printoptions(precision=8)\n",
        "seed=99\n",
        "\n",
        "print(tf. __version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the directory to data location\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/PINN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUgWbGEkQPxl",
        "outputId": "e6ba9283-7c3e-4ee7-ae57-98ba7697749e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file\n",
        "file = 'molar_fraction_major_chemical_marker.hdf5'\n",
        "f = h5py.File(file, 'r')"
      ],
      "metadata": {
        "id": "CpDmUOMOQ-Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the feature and the label\n",
        "# The dataset have larger points HHR region [data= Augumentation]\n",
        "dataset = np.array(f.get('molar_fraction'))\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quMBHYSdRSHd",
        "outputId": "60e27844-d0a3-4306-86bc-ef49b6a9059b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50901851, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the feature and the label\n",
        "X_old = dataset[:,:-1]\n",
        "Y = dataset[:,[-1]]\n",
        "print(X_old.shape,Y.shape)"
      ],
      "metadata": {
        "id": "ToYJuMmdRWON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9142c4-9edd-4ac4-9ef9-5cb184ad50b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50901851, 5) (50901851, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the product of mass fraction and density to find mole fraction.\n",
        "# get the mass fraction\n",
        "y_nh = X_old[:,0:1]\n",
        "y_nh2 = X_old[:,1:2]\n",
        "y_oh = X_old[:,2:3]\n",
        "# Get the tmperature{The additional input}\n",
        "temp = X_old[:,4:5]\n",
        "# get the density\n",
        "density = X_old[:,3:4]\n",
        "\n",
        "# A linear relation between mass fractio and mole fraction\n",
        "X_nh = y_nh *density\n",
        "X_nh2 = y_nh2 *density\n",
        "X_oh = y_oh *density\n",
        "\n",
        "# The new input\n",
        "X = np.c_[X_nh,X_nh2,X_oh,temp]\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCtDytYydlGP",
        "outputId": "a58cf74a-94d4-4c7b-c611-786f3449c272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.24108411e-07 7.15551340e-06 1.50022992e-04 1.88831462e+03]\n",
            " [3.24264966e-07 7.15909405e-06 1.50018731e-04 1.88830965e+03]\n",
            " [3.24387130e-07 7.16189148e-06 1.50015388e-04 1.88830574e+03]\n",
            " ...\n",
            " [1.03291829e-05 3.26863957e-05 8.84004547e-04 2.29063320e+03]\n",
            " [1.01743229e-05 3.21374957e-05 8.88756537e-04 2.29142432e+03]\n",
            " [9.85278722e-06 3.10329526e-05 8.92953618e-04 2.29242941e+03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the datattype\n",
        "X = np.float32(X)\n",
        "Y = np.float32(Y)\n"
      ],
      "metadata": {
        "id": "SpAxyPjti1X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle the dataset\n",
        "X,Y = shuffle(X, Y, random_state=seed)\n",
        "print(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VqRjjoVRjux",
        "outputId": "961aa224-e328-4452-809b-6b189ff32d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.1436125e-05 6.6332905e-05 9.4569393e-04 1.8394366e+03]\n",
            " [2.3975999e-05 3.6371115e-04 1.9834892e-04 1.5187620e+03]\n",
            " [5.1061328e-05 5.8826891e-04 1.4799622e-04 1.7107389e+03]\n",
            " ...\n",
            " [3.0624233e-05 4.4022195e-04 2.0987148e-04 1.5530289e+03]\n",
            " [4.0838397e-05 2.8424856e-04 6.6376093e-04 1.8717084e+03]\n",
            " [3.5612813e-06 1.4560942e-04 2.2836184e-05 1.4690447e+03]] [[2.6408230e+09]\n",
            " [4.5877038e+09]\n",
            " [8.5497395e+09]\n",
            " ...\n",
            " [6.0870994e+09]\n",
            " [8.8248003e+09]\n",
            " [2.3323902e+08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "epsilon = 1e-10\n",
        "Y_n = (Y - np.min(Y) + epsilon  *(np.max(Y)-np.min(Y)))/ (np.max(Y)-np.min(Y) + epsilon   * (np.max(Y)-np.min(Y)))\n",
        "X_n = (X - np.min(X, axis=0) + epsilon  *(np.max(X, axis=0)-np.min(X, axis=0)))/ (np.max(X, axis=0)-np.min(X, axis=0) + epsilon  * (np.max(X, axis=0)-np.min(X, axis=0)))"
      ],
      "metadata": {
        "id": "ALK-KTT6V90J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # create the normalization fit \n",
        "# scale_X = MinMaxScaler()\n",
        "# scale_Y = MinMaxScaler()\n",
        "\n",
        "# # The fit function\n",
        "# print(scale_X.fit(X))\n",
        "# print(scale_Y.fit(Y))\n",
        "print(X_n,Y_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP7N8_Z_RnZ0",
        "outputId": "0957eb62-5e74-4f3a-c22a-3a281d3e598a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.12565005 0.0882831  0.546299   0.58453494]\n",
            " [0.2634644  0.48807305 0.11424741 0.37687802]\n",
            " [0.5611346  0.78996444 0.08513775 0.5011951 ]\n",
            " ...\n",
            " [0.33652908 0.5909328  0.12090877 0.39906803]\n",
            " [0.44878367 0.381245   0.3833092  0.6054329 ]\n",
            " [0.0391048  0.19486102 0.01278082 0.34468296]] [[0.13353658]\n",
            " [0.23251079]\n",
            " [0.43393013]\n",
            " ...\n",
            " [0.30873606]\n",
            " [0.44791347]\n",
            " [0.01114142]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_train split \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y_n, test_size=0.1)\n",
        "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxvxtlw9RqRt",
        "outputId": "e14e58c1-7f6a-482a-fc9b-f1b4fb4bd435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45811665, 4) (5090186, 4) (45811665, 1) (5090186, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # normalize the train data and label\n",
        "# X_train_n = scale_X.transform(X_train)\n",
        "# Y_train_n = scale_Y.transform(Y_train)\n",
        "# print(X_train_n)\n",
        "# print(Y_train_n)"
      ],
      "metadata": {
        "id": "HiW6mUjtR7yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the chunk \n",
        "X_chunk = tf.Variable(X_train)\n",
        "Y_chunk = tf.Variable(Y_train)\n",
        "print(X_chunk, Y_chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efe9FJ4bRs1w",
        "outputId": "e507a924-ac28-49a5-b481-b4d1217ffa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(45811665, 4) dtype=float32, numpy=\n",
            "array([[0.0233122 , 0.16263473, 0.00569963, 0.20774056],\n",
            "       [0.52587634, 0.63037336, 0.08785675, 0.61297464],\n",
            "       [0.11136776, 0.46825173, 0.00814626, 0.26391652],\n",
            "       ...,\n",
            "       [0.5899217 , 0.6467477 , 0.22106957, 0.5422071 ],\n",
            "       [0.4257508 , 0.25201622, 0.19658317, 0.8839737 ],\n",
            "       [0.08465935, 0.3928106 , 0.01286309, 0.13305877]], dtype=float32)> <tf.Variable 'Variable:0' shape=(45811665, 1) dtype=float32, numpy=\n",
            "array([[0.00930248],\n",
            "       [0.2805789 ],\n",
            "       [0.06084422],\n",
            "       ...,\n",
            "       [0.5775659 ],\n",
            "       [0.11447497],\n",
            "       [0.07792261]], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaate the batch slices.\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_chunk, Y_chunk))\n",
        "train_data = train_data.batch(2048, drop_remainder=True)\n",
        "print(train_data)\n",
        "# test_data = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "# test_data = test_data.batch(1024, drop_remainder=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcRu3iqFRvmP",
        "outputId": "2a2a8875-47bf-4749-9b52-2b2d8ef20cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: ((2048, 4), (2048, 1)), types: (tf.float32, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the pretrained model\n",
        "# Read the file\n",
        "file = 'model_with_molar_fraction_major_CM.h5'\n",
        "model = tf.keras.models.load_model(file)\n",
        "\n",
        "# Get summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxvATXwSSFVd",
        "outputId": "7d21b34e-63f6-4f3d-9a20-dd7d80e6742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Heat_release_rate\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " h_layer1 (Dense)            (None, 40)                200       \n",
            "                                                                 \n",
            " h_layer2 (Dense)            (None, 24)                984       \n",
            "                                                                 \n",
            " h_layer3 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " output_layers (Dense)       (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,809\n",
            "Trainable params: 1,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Ki the is respective exponents of the species massfraction and temperature, which could yeild us a perfect reconstruction of the HRR\n",
        "k1,k2,k3,k4,k5 = tf.Variable(-1.8),tf.Variable(-1.6),tf.Variable(-1.4),tf.Variable(-1.5),tf.Variable(1.3)"
      ],
      "metadata": {
        "id": "1UxmRzwuSRJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The customized mean square error, taking the batch data at any instance\n",
        "def customized_MSE(true, pred):\n",
        "    MSE = tf.reduce_mean(tf.square(true-pred))\n",
        "    return MSE\n",
        "# The customized loss taking the non-linear equation as residual\n",
        "def total_mse(MSE_NN, x, y, k1, k2, k3, k4, k5):# the MSE_NN is the mean squared error of the neural network \n",
        "    residual = tf.square(tf.math.log(y) - (k1 * tf.math.log(x[:,0:1]) + k2 * tf.math.log(x[:,1:2]) + k3 * tf.math.log(x[:,2:3]) + k4 * tf.math.log(x[:,3:4]) + tf.math.log(k5)))\n",
        "    MSE_func = tf.reduce_mean(residual)\n",
        "    total =  MSE_NN + MSE_func\n",
        "    return total"
      ],
      "metadata": {
        "id": "P8f5MrnPSUlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The optimizer\n",
        "# optimizer= tf.keras.optimizers.SGD(learning_rate=0.3,momentum=0.8)\n",
        "optimizers = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.03, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        "    name='Adam')"
      ],
      "metadata": {
        "id": "zD_2ptNKSW5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training with customized optimization technic (Automatic-Gradient)\n",
        "epochs = 25\n",
        "#lr_rate = 0.03\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Starting a new epoch\",epoch+1)\n",
        "  for step, (X_batch, Y_batch) in enumerate(train_data):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      Y_pred = model(X_batch)\n",
        "      current_loss = customized_MSE(Y_batch,Y_pred)\n",
        "      new_loss = total_mse(current_loss, X_batch, Y_batch, k1, k2, k3, k4, k5)\n",
        "\n",
        "    # The gradient check  \n",
        "    gradient = tape.gradient(new_loss, [k1,k2,k3,k4,k5])\n",
        "    grad = tape.gradient(current_loss, model.trainable_variables)\n",
        "\n",
        "    #Assign new variables to the model using optimizer isntead of sub assign\n",
        "    optimizers.apply_gradients(zip(grad, model.trainable_variables))\n",
        "    optimizers.apply_gradients(zip(gradient, [k1,k2,k3,k4,k5]))\n",
        "  \n",
        "  print(\"k1:{} k2:{} k3:{} k4:{} k5:{}\".format(k1.numpy(),k2.numpy(),k3.numpy(),k4.numpy(),k5.numpy()))\n",
        "  print(\"current_Loss: {} new_loss: {}\".format(current_loss.numpy(), new_loss.numpy()))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di-n5ZxVa_5q",
        "outputId": "d7ec608b-9c38-4463-a3e3-a0e4a6035f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting a new epoch 1\n",
            "k1:0.9253278374671936 k2:0.17793548107147217 k3:0.6602041125297546 k4:-1.5913439989089966 k5:0.9866951107978821\n",
            "current_Loss: 6.717333599226549e-05 new_loss: 0.15743225812911987\n",
            "Starting a new epoch 2\n",
            "k1:0.9253277778625488 k2:0.17793557047843933 k3:0.6602041125297546 k4:-1.591343641281128 k5:0.9866951704025269\n",
            "current_Loss: 0.00010370668314862996 new_loss: 0.15746881067752838\n",
            "Starting a new epoch 3\n",
            "k1:0.9253278970718384 k2:0.17793549597263336 k3:0.6602041721343994 k4:-1.5913439989089966 k5:0.9866951704025269\n",
            "current_Loss: 0.00011268029629718512 new_loss: 0.15747776627540588\n",
            "Starting a new epoch 4\n",
            "k1:0.9253278970718384 k2:0.17793545126914978 k3:0.6602041721343994 k4:-1.591343879699707 k5:0.9866951704025269\n",
            "current_Loss: 8.474945207126439e-05 new_loss: 0.1574498564004898\n",
            "Starting a new epoch 5\n",
            "k1:0.925327718257904 k2:0.17793552577495575 k3:0.6602041125297546 k4:-1.591343641281128 k5:0.9866951107978821\n",
            "current_Loss: 4.0901351894717664e-05 new_loss: 0.15740598738193512\n",
            "Starting a new epoch 6\n",
            "k1:0.9253278970718384 k2:0.1779354065656662 k3:0.6602041125297546 k4:-1.591343879699707 k5:0.9866949319839478\n",
            "current_Loss: 4.99966845382005e-05 new_loss: 0.15741510689258575\n",
            "Starting a new epoch 7\n",
            "k1:0.9253278374671936 k2:0.17793554067611694 k3:0.6602039933204651 k4:-1.5913437604904175 k5:0.9866950511932373\n",
            "current_Loss: 4.841003828914836e-05 new_loss: 0.15741349756717682\n",
            "Starting a new epoch 8\n",
            "k1:0.9253277778625488 k2:0.17793560028076172 k3:0.6602041125297546 k4:-1.5913437604904175 k5:0.9866952300071716\n",
            "current_Loss: 3.833321534330025e-05 new_loss: 0.15740340948104858\n",
            "Starting a new epoch 9\n",
            "k1:0.9253278374671936 k2:0.17793551087379456 k3:0.6602040529251099 k4:-1.5913437604904175 k5:0.9866950511932373\n",
            "current_Loss: 3.769509567064233e-05 new_loss: 0.15740278363227844\n",
            "Starting a new epoch 10\n",
            "k1:0.9253277778625488 k2:0.17793549597263336 k3:0.6602040529251099 k4:-1.5913437604904175 k5:0.9866951704025269\n",
            "current_Loss: 5.8562167396303266e-05 new_loss: 0.15742364525794983\n",
            "Starting a new epoch 11\n",
            "k1:0.9253278970718384 k2:0.17793536186218262 k3:0.6602040529251099 k4:-1.591343879699707 k5:0.9866951107978821\n",
            "current_Loss: 6.088595182518475e-05 new_loss: 0.15742598474025726\n",
            "Starting a new epoch 12\n",
            "k1:0.9253278374671936 k2:0.17793546617031097 k3:0.6602041721343994 k4:-1.5913437604904175 k5:0.9866951107978821\n",
            "current_Loss: 2.7740314180846326e-05 new_loss: 0.15739282965660095\n",
            "Starting a new epoch 13\n",
            "k1:0.925327718257904 k2:0.1779356151819229 k3:0.6602041721343994 k4:-1.591343879699707 k5:0.9866951704025269\n",
            "current_Loss: 2.7657239115796983e-05 new_loss: 0.15739275515079498\n",
            "Starting a new epoch 14\n",
            "k1:0.9253278970718384 k2:0.17793533205986023 k3:0.6602041125297546 k4:-1.5913439989089966 k5:0.9866950511932373\n",
            "current_Loss: 3.2490530429640785e-05 new_loss: 0.1573975831270218\n",
            "Starting a new epoch 15\n",
            "k1:0.925327718257904 k2:0.17793555557727814 k3:0.6602041125297546 k4:-1.591343879699707 k5:0.9866949915885925\n",
            "current_Loss: 4.2375399061711505e-05 new_loss: 0.1574074625968933\n",
            "Starting a new epoch 16\n",
            "k1:0.9253278970718384 k2:0.1779354363679886 k3:0.6602041125297546 k4:-1.5913437604904175 k5:0.9866950511932373\n",
            "current_Loss: 4.094782707397826e-05 new_loss: 0.1574060320854187\n",
            "Starting a new epoch 17\n",
            "k1:0.9253277778625488 k2:0.17793545126914978 k3:0.6602041125297546 k4:-1.591343879699707 k5:0.9866951107978821\n",
            "current_Loss: 3.7622252420987934e-05 new_loss: 0.15740270912647247\n",
            "Starting a new epoch 18\n",
            "k1:0.9253278374671936 k2:0.1779354363679886 k3:0.6602041125297546 k4:-1.5913439989089966 k5:0.9866951107978821\n",
            "current_Loss: 3.4222401154693216e-05 new_loss: 0.15739932656288147\n",
            "Starting a new epoch 19\n",
            "k1:0.9253278970718384 k2:0.17793551087379456 k3:0.6602041721343994 k4:-1.5913439989089966 k5:0.9866951107978821\n",
            "current_Loss: 3.472263415460475e-05 new_loss: 0.15739981830120087\n",
            "Starting a new epoch 20\n",
            "k1:0.9253277778625488 k2:0.17793552577495575 k3:0.6602041721343994 k4:-1.5913437604904175 k5:0.9866951107978821\n",
            "current_Loss: 2.8006561478832737e-05 new_loss: 0.15739308297634125\n",
            "Starting a new epoch 21\n",
            "k1:0.9253278970718384 k2:0.1779354214668274 k3:0.6602041125297546 k4:-1.5913437604904175 k5:0.9866949915885925\n",
            "current_Loss: 3.504109554341994e-05 new_loss: 0.15740014612674713\n",
            "Starting a new epoch 22\n",
            "k1:0.9253278374671936 k2:0.17793558537960052 k3:0.6602041125297546 k4:-1.591343879699707 k5:0.9866951704025269\n",
            "current_Loss: 3.1704676075605676e-05 new_loss: 0.1573968231678009\n",
            "Starting a new epoch 23\n",
            "k1:0.9253278374671936 k2:0.177935391664505 k3:0.6602041721343994 k4:-1.5913437604904175 k5:0.9866950511932373\n",
            "current_Loss: 2.9410708521027118e-05 new_loss: 0.15739449858665466\n",
            "Starting a new epoch 24\n",
            "k1:0.925327718257904 k2:0.17793558537960052 k3:0.6602041125297546 k4:-1.591343641281128 k5:0.9866952300071716\n",
            "current_Loss: 3.20988692692481e-05 new_loss: 0.15739718079566956\n",
            "Starting a new epoch 25\n",
            "k1:0.9253278374671936 k2:0.17793546617031097 k3:0.6602041125297546 k4:-1.591343879699707 k5:0.9866951107978821\n",
            "current_Loss: 3.150897100567818e-05 new_loss: 0.1573966145515442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Training with customized optimization technic (Automatic-Gradient)\n",
        "# epochs = 25\n",
        "# lr_rate = 0.03\n",
        "\n",
        "# for epoch in range(epochs):\n",
        "#   print(\"Starting a new epoch\",epoch+1)\n",
        "#   for step, (X_batch, Y_batch) in enumerate(train_data):\n",
        "#     with tf.GradientTape(persistent=True) as tape:\n",
        "#       Y_pred = model(X_batch)\n",
        "#       current_loss = customized_MSE(Y_batch,Y_pred)\n",
        "#       new_loss = total_mse(current_loss, X_batch, Y_batch, k1, k2, k3, k4, k5)\n",
        "\n",
        "#     # The gradient check  \n",
        "#     gradient = tape.gradient(new_loss, [k1,k2,k3,k4,k5])\n",
        "#     grad = tape.gradient(current_loss, model.trainable_variables)\n",
        "\n",
        "#     #Assign new variables to the model using optimizer isntead of sub assign\n",
        "#     optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
        "\n",
        "#     #Update the Ki to reduce the residual\n",
        "#     k1.assign_sub(gradient[0]*lr_rate)\n",
        "#     k2.assign_sub(gradient[1]*lr_rate)\n",
        "#     k3.assign_sub(gradient[2]*lr_rate)\n",
        "#     k4.assign_sub(gradient[3]*lr_rate)\n",
        "#     k5.assign_sub(gradient[4]*lr_rate)\n",
        "  \n",
        "#   print(\"k1:{} k2:{} k3:{} k4:{} k5:{}\".format(k1.numpy(),k2.numpy(),k3.numpy(),k4.numpy(), k5.numpy()))\n",
        "#   print(\"current_Loss: {} new_loss: {}\".format(current_loss.numpy(), new_loss.numpy()))  "
      ],
      "metadata": {
        "id": "9lFkV7IZSZEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a451d8c6-b215-48f1-dd48-b227faa3df56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting a new epoch 1\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9711529097985476e-05 new_loss: 0.15844884514808655\n",
            "Starting a new epoch 2\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.971100159105845e-05 new_loss: 0.15844884514808655\n",
            "Starting a new epoch 3\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.97089243051596e-05 new_loss: 0.15844884514808655\n",
            "Starting a new epoch 4\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.970593388658017e-05 new_loss: 0.15844884514808655\n",
            "Starting a new epoch 5\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.970246689277701e-05 new_loss: 0.15844883024692535\n",
            "Starting a new epoch 6\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.969898170907982e-05 new_loss: 0.15844883024692535\n",
            "Starting a new epoch 7\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.969482349930331e-05 new_loss: 0.15844883024692535\n",
            "Starting a new epoch 8\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9690527046332136e-05 new_loss: 0.15844883024692535\n",
            "Starting a new epoch 9\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9685710362391546e-05 new_loss: 0.15844881534576416\n",
            "Starting a new epoch 10\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.968120290664956e-05 new_loss: 0.15844881534576416\n",
            "Starting a new epoch 11\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9675753214396536e-05 new_loss: 0.15844881534576416\n",
            "Starting a new epoch 12\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.967021621065214e-05 new_loss: 0.15844880044460297\n",
            "Starting a new epoch 13\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.966389340348542e-05 new_loss: 0.15844880044460297\n",
            "Starting a new epoch 14\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.965740688727237e-05 new_loss: 0.15844878554344177\n",
            "Starting a new epoch 15\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.965013092965819e-05 new_loss: 0.15844878554344177\n",
            "Starting a new epoch 16\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9642647607252e-05 new_loss: 0.15844877064228058\n",
            "Starting a new epoch 17\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9634600398130715e-05 new_loss: 0.15844877064228058\n",
            "Starting a new epoch 18\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9626167563255876e-05 new_loss: 0.15844875574111938\n",
            "Starting a new epoch 19\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9617050788365304e-05 new_loss: 0.15844875574111938\n",
            "Starting a new epoch 20\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.960717003792524e-05 new_loss: 0.1584487408399582\n",
            "Starting a new epoch 21\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9597274735569954e-05 new_loss: 0.158448725938797\n",
            "Starting a new epoch 22\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.958614252042025e-05 new_loss: 0.158448725938797\n",
            "Starting a new epoch 23\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9575159462401643e-05 new_loss: 0.1584487110376358\n",
            "Starting a new epoch 24\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.956315777031705e-05 new_loss: 0.1584486961364746\n",
            "Starting a new epoch 25\n",
            "k1:0.9110038876533508 k2:0.18080781400203705 k3:0.6620661020278931 k4:-1.582798719406128 k5:0.9866163730621338\n",
            "current_Loss: 3.9551454392494634e-05 new_loss: 0.15844868123531342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Th9wSkRLBSUk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}